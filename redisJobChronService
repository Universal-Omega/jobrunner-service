#!/usr/bin/env php
<?php

if ( PHP_SAPI !== 'cli' ) {
	die( "This is not a valid entry point.\n" );
} elseif ( !class_exists( 'Redis' ) ) {
	die( "The phpredis extension is not installed; aborting.\n" );
}

require( __DIR__ . '/src/RedisJobService.php' );

class RedisJobChronService extends RedisJobService {
	const TASK_PERIOD_SEC = 60;

	/**
	 * Entry point method that starts the service in earnest and keeps running
	 */
	public function main() {
		$this->notice( "Starting job chron loop(s)..." );

		$host = gethostname();

		// Setup signal handlers
		$useSignals = function_exists( 'pcntl_signal' );
		if ( $useSignals ) {
			$handlerFunc = function( $signo ) {
				print "Caught signal ($signo)\n";
				exit( 128 + $signo );
			};
			$ok = pcntl_signal( SIGHUP, $handlerFunc )
				&& pcntl_signal( SIGINT, $handlerFunc )
				&& pcntl_signal( SIGTERM, $handlerFunc );
			if ( !$ok ) {
				throw new Exception( 'Could not install singal handlers.' );
			}
		}

		$memLast = memory_get_usage();
		$this->incrStats( "start-chron.$host", 1 );
		while ( true ) {
			if ( $useSignals ) {
				pcntl_signal_dispatch();
			}

			// Do periodic queue tasks on all queues every 5 minutes
			$count = $this->executeReadyPeriodicTasks();
			if ( is_int( $count ) ) {
				$this->notice( "Updated the state of $count job(s) (recycle/undelay/abandon)." );
				$this->incrStats( "periodictasks.done.$host", 1 );
			}
			sleep( 1 );
			// Track memory usage
			$memCurrent = memory_get_usage();
			$this->debug( "Memory usage: $memCurrent bytes." );
			$this->incrStats( "memory.$host", $memCurrent - $memLast );
			$memLast = $memCurrent;
		}
	}

	/**
	 * Recycle or destroy any jobs that have been claimed for too long
	 * and release any ready delayed jobs into the queue. Also abandon
	 * and prune out jobs that failed too many times. This updates the
	 * aggregator server as necessary.
	 *
	 * @note: similar to JobQueueRedis.php periodic tasks method
	 * @return int|bool Number of jobs recycled/deleted/undelayed/abandoned (false if not run)
	 */
	private function executeReadyPeriodicTasks() {
		$jobs = 0;

		// Run no more than every 5 minutes.
		// This is randomized to scale the liveliness with the # of runners.
		static $lastPeriodicTime = null;
		$lastPeriodicTime = $lastPeriodicTime ?: time() - mt_rand( 0, self::TASK_PERIOD_SEC );
		if ( ( time() - $lastPeriodicTime ) <= self::TASK_PERIOD_SEC ) {
			return false;
		}
		$lastPeriodicTime = time();

		$host = gethostname();

		$aConn = false;
		// Connect to the first working server on the list
		foreach ( $this->aggrSrvs as $aServer ) {
			$aConn = $this->getRedisConn( $aServer );
			if ( $aConn ) {
				break;
			}
		}

		if ( !$aConn ) {
			$this->incrStats( "periodictasks.failed.$host", 1 );
			return $jobs;
		}

		$ok = true;
		try {
			$types = $this->redisCmd( $aConn, 'hKeys', array( $this->getQueueTypesKey() ) );
			$wikiIds = $this->redisCmd( $aConn, 'sMembers', array( $this->getWikiSetKey() ) );
			if ( !is_array( $types ) || !is_array( $wikiIds ) ) {
				$this->incrStats( "periodictasks.failed.$host", 1 );
				return $jobs;
			}

			// Randomize to scale the liveliness with the # of runners
			shuffle( $types );
			shuffle( $wikiIds );

			$now = time();

			// Build up the script arguments for each queue...
			$paramsByQueue = array();
			foreach ( $types as $type ) {
				$ttl = $this->getTTLForType( $type );
				$attempts = $this->getAttemptsForType( $type );
				foreach ( $wikiIds as $wikiId ) {
					$paramsByQueue[] = array(
						'queue'  => array( $type, $wikiId ),
						'params' => array(
							"{$wikiId}:jobqueue:{$type}:z-claimed", # KEYS[1]
							"{$wikiId}:jobqueue:{$type}:h-attempts", # KEYS[2]
							"{$wikiId}:jobqueue:{$type}:l-unclaimed", # KEYS[3]
							"{$wikiId}:jobqueue:{$type}:h-data", # KEYS[4]
							"{$wikiId}:jobqueue:{$type}:z-abandoned", # KEYS[5]
							"{$wikiId}:jobqueue:{$type}:z-delayed", # KEYS[6]
							$now - $ttl, # ARGV[1]
							$now - 7 * 86400, # ARGV[2]
							$attempts, # ARGV[3]
							$now # ARGV[4]
						),
						'keys'   => 6 # number of first argument(s) that are keys
					);
				}
			}
			// Batch the Lua queries to avoid client OOMs
			$paramsByQueueBatches = array_chunk( $paramsByQueue, 1000 );

			$mapSet = array(); // ready map of (queue name => timestamp)
			// Run the script on all job queue partitions...
			foreach ( $this->queueSrvs as $qServer ) {
				foreach ( $paramsByQueueBatches as $paramsByQueueBatch ) {
					$ok = $this->updateQueueServer(
						$qServer, $paramsByQueueBatch, $mapSet, $jobs ) && $ok;
				}
			}
			// Update the map in the aggregator as queues become ready
			$this->redisCmd( $aConn, 'hMSet', array( $this->getReadyQueueKey(), $mapSet ) );
		} catch ( RedisException $e ) {
			$ok = false;
			$this->handleRedisError( $e, $aServer );
		}

		if ( !$ok ) {
			$this->error( "Failed to do periodic tasks for some queues." );
		}

		return $jobs;
	}

	private function updateQueueServer( $qServer, array $paramsByQueue, array &$mapSet, &$jobs ) {
		$host = gethostname();

		$qConn = $this->getRedisConn( $qServer );
		if ( !$qConn ) {
			$this->incrStats( "periodictasks.failed.$host", count( $paramsByQueue ) );
			return false; // partition down
		}

		static $script =
<<<LUA
		local kClaimed, kAttempts, kUnclaimed, kData, kAbandoned, kDelayed = unpack(KEYS)
		local rClaimCutoff, rPruneCutoff, rAttempts, rTime = unpack(ARGV)
		local released,abandoned,pruned,undelayed,ready = 0,0,0,0,0
		-- Get all non-dead jobs that have an expired claim on them.
		-- The score for each item is the last claim timestamp (UNIX).
		local staleClaims = redis.call('zRangeByScore',kClaimed,0,rClaimCutoff)
		for k,id in ipairs(staleClaims) do
			local timestamp = redis.call('zScore',kClaimed,id)
			local attempts = redis.call('hGet',kAttempts,id)
			if attempts < rAttempts then
				-- Claim expired and attempts left: re-enqueue the job
				redis.call('lPush',kUnclaimed,id)
				released = released + 1
			else
				-- Claim expired and no attempts left: mark the job as dead
				redis.call('zAdd',kAbandoned,timestamp,id)
				abandoned = abandoned + 1
			end
			redis.call('zRem',kClaimed,id)
		end
		-- Get all of the dead jobs that have been marked as dead for too long.
		-- The score for each item is the last claim timestamp (UNIX).
		local deadClaims = redis.call('zRangeByScore',kAbandoned,0,rPruneCutoff)
		for k,id in ipairs(deadClaims) do
			-- Stale and out of attempts: remove any traces of the job
			redis.call('zRem',kAbandoned,id)
			redis.call('hDel',kAttempts,id)
			redis.call('hDel',kData,id)
			pruned = pruned + 1
		end
		-- Get the list of ready delayed jobs, sorted by readiness (UNIX timestamp)
		local ids = redis.call('zRangeByScore',kDelayed,0,rTime)
		-- Migrate the jobs from the "delayed" set to the "unclaimed" list
		for k,id in ipairs(ids) do
			redis.call('lPush',kUnclaimed,id)
			redis.call('zRem',kDelayed,id)
		end
		undelayed = #ids
		ready = redis.call('lLen',kUnclaimed)
		return {released,abandoned,pruned,undelayed,ready}
LUA;

		$failed = 0;
		try {
			$sha1 = $this->redisCmd( $qConn, 'script', array( 'load', $script ) );

			$this->redisCmd( $qConn, 'multi', array( Redis::PIPELINE ) );
			foreach ( $paramsByQueue as $params ) {
				$this->redisCmd( $qConn, 'evalSha',
					array( $sha1, $params['params'], $params['keys'] ) );
			}
			$res = $this->redisCmd( $qConn, 'exec' );

			$now = time();
			foreach ( $res as $i => $result ) {
				if ( !$result ) {
					++$failed;
					continue;
				}
				list( $qType, $qWiki ) = $paramsByQueue[$i]['queue'];
				list( $released, $abandoned, $pruned, $undelayed, $ready ) = $result;
				if ( $released > 0 || $undelayed > 0 || $ready > 0 ) {
					// This checks $ready to handle lost aggregator updates as well as
					// to merge after network partitions that caused aggregator fail-over.
					$mapSet[$this->encQueueName( $qType, $qWiki )] = $now;
				}
				$jobs += ( array_sum( $result ) - $ready );
				$this->incrStats( "job-recycle.$qType.$qWiki", $released );
				$this->incrStats( "job-abandon.$qType.$qWiki", $abandoned );
				$this->incrStats( "job-undelay.$qType.$qWiki", $undelayed );
			}
		} catch ( RedisException $e ) {
			$failed += count( $paramsByQueue );
			$this->handleRedisError( $e, $qServer );
		}

		$this->incrStats( "periodictasks.failed.$host", $failed );

		return ( $failed == 0 );
	}

	/**
	 * @param string $type Queue type
	 * @return integer Seconds
	 */
	protected function getTTLForType( $type ) {
		return isset( $this->claimTTLMap[$type] )
			? $this->claimTTLMap[$type]
			: $this->claimTTLMap['*'];
	}

	/**
	 * @param string $type Queue type
	 * @return integer
	 */
	protected function getAttemptsForType( $type ) {
		return isset( $this->attemptsMap[$type] )
			? $this->attemptsMap[$type]
			: $this->attemptsMap['*'];
	}
}

error_reporting( E_ALL | E_STRICT );
ini_set( 'display_errors', 1 );

// Run the server...
set_time_limit( 0 );
ini_set( 'memory_limit', '256M' );
RedisJobChronService::init(
	getopt( '', array( 'config-file::', 'help', 'verbose' ) )
)->main();
